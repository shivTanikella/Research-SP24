{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]] \n",
      "\n",
      "y:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#  loading in data set\n",
    "cancer = load_breast_cancer(as_frame=False) # change 'as_frame' to 'True' if you want to see features\n",
    "X, y = cancer.data, cancer.target\n",
    "print(f'X:{X} \\n\\ny:{y}')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
    "# print(len(X_train), len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier from sklearn\n",
    "\n",
    "cancer_test = DecisionTreeClassifier(criterion='gini')\n",
    "cancer_test.fit(X_train, y_train)\n",
    "\n",
    "pred = cancer_test.predict(X_test)\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (incomplete) DecisionTreeClassifier from scratch\n",
    "class DecisionNode:\n",
    "    def __init__(self, feature_i=None, threshold=None, value=None, true_branch=None, false_branch=None):\n",
    "        self.feature_i = feature_i\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "def divide_on_feature(X, feature_i, threshold):\n",
    "    split_func = None\n",
    "    if isinstance(threshold, int) or isinstance(threshold, float):\n",
    "        split_func = lambda sample: sample[feature_i] >= threshold\n",
    "    else:\n",
    "        split_func = lambda sample: sample[feature_i] == threshold\n",
    "\n",
    "    X_1 = np.array([sample for sample in X if split_func(sample)])\n",
    "    X_2 = np.array([sample for sample in X if not split_func(sample)])\n",
    "\n",
    "    return [X_1, X_2]  # return a list of arrays instead of a numpy array of arrays\n",
    "\n",
    "\n",
    "class my_DecisionTreeClassifier(object):\n",
    "    def __init__(self, min_samples_split=2, min_impurity=1e-7, max_depth=float('inf'), loss=None):\n",
    "        self.root = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_impurity = min_impurity\n",
    "        self.max_depth = max_depth\n",
    "        self._impurity_calculation = None\n",
    "        self._leaf_value_calculation = None\n",
    "        self.one_dim = None\n",
    "        self.loss = loss\n",
    "\n",
    "    def _calculate_gini(self, y):\n",
    "        classes = np.unique(y)\n",
    "        impurity = 1\n",
    "        for cls in classes:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            impurity -= p_cls**2\n",
    "        return impurity\n",
    "    \n",
    "    def _calculate_leaf_value(self, y):\n",
    "        return stats.mode(y)[0]\n",
    "\n",
    "\n",
    "    def fit(self, X, y, loss=None):\n",
    "        self.one_dim = len(np.shape(y)) == 1\n",
    "        self._impurity_calculation = self._calculate_gini\n",
    "        self._leaf_value_calculation = self._calculate_leaf_value\n",
    "        self.root = self._build_tree(X, y)\n",
    "        self.loss=None\n",
    "\n",
    "    def _build_tree(self, X, y, current_depth=0):\n",
    "        largest_impurity = 0\n",
    "        best_criteria = None\n",
    "        best_sets = None\n",
    "\n",
    "        if len(np.shape(y)) == 1:\n",
    "            y = np.expand_dims(y, axis=1)\n",
    "\n",
    "        Xy = np.concatenate((X, y), axis=1)\n",
    "\n",
    "        n_samples, n_features = np.shape(X)\n",
    "\n",
    "        if n_samples >= self.min_samples_split and current_depth <= self.max_depth:\n",
    "            for feature_i in range(n_features):\n",
    "                feature_values = np.expand_dims(X[:, feature_i], axis=1)\n",
    "                unique_values = np.unique(feature_values)\n",
    "\n",
    "                for threshold in unique_values:\n",
    "                    Xy1, Xy2 = divide_on_feature(Xy, feature_i, threshold)[0], divide_on_feature(Xy, feature_i, threshold)[1]\n",
    "                    if len(Xy1) > 0 and len(Xy2) > 0:\n",
    "                        y1 = Xy1[:, n_features:]\n",
    "                        y2 = Xy2[:, n_features:]\n",
    "\n",
    "                        impurity1 = self._calculate_gini(y1)\n",
    "                        impurity2 = self._calculate_gini(y2)\n",
    "                        impurity = (len(y1) * impurity1 + len(y2) * impurity2) / len(y)\n",
    "\n",
    "                        if impurity > largest_impurity:\n",
    "                            largest_impurity = impurity\n",
    "                            best_criteria = {\"feature_i\": feature_i, \"threshold\": threshold}\n",
    "                            best_sets = {\n",
    "                                \"leftX\": Xy1[:, :n_features],\n",
    "                                \"lefty\": Xy1[:, n_features:],\n",
    "                                \"rightX\": Xy2[:, :n_features],\n",
    "                                \"righty\": Xy2[:, n_features:],\n",
    "                            }\n",
    "\n",
    "        if largest_impurity > self.min_impurity:\n",
    "            true_branch = self._build_tree(best_sets[\"leftX\"], best_sets[\"lefty\"], current_depth + 1)\n",
    "            false_branch = self._build_tree(best_sets[\"rightX\"], best_sets[\"righty\"], current_depth + 1)\n",
    "            return DecisionNode(feature_i=best_criteria[\"feature_i\"], threshold=best_criteria[\"threshold\"], true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "        leaf_value = self._leaf_value_calculation(y)\n",
    "\n",
    "        return DecisionNode(value=leaf_value)\n",
    "\n",
    "    def predict_value(self, x, tree=None):\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "\n",
    "        feature_value = x[tree.feature_i]\n",
    "\n",
    "        branch = tree.false_branch\n",
    "        if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
    "            if feature_value >= tree.threshold:\n",
    "                branch = tree.true_branch\n",
    "        elif feature_value == tree.threshold:\n",
    "            branch = tree.true_branch\n",
    "\n",
    "        return self.predict_value(x, branch)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self.predict_value(sample) for sample in X]\n",
    "        return y_pred\n",
    "\n",
    "cancer_test2 = my_DecisionTreeClassifier(max_depth = 10)\n",
    "cancer_test2.fit(X_train, y_train)\n",
    "vals = cancer_test2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals2 = []\n",
    "\n",
    "for i in range(len(vals)):\n",
    "    vals2.append(int(float(''.join(map(str,vals[i])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold cv from sklearn\n",
    "def sklearn_cv_score(dataset, X, y, k):\n",
    "    cvs = cross_val_score(estimator = dataset, X=X, y=y, cv=k)\n",
    "    print(cvs)\n",
    "    return cvs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold cv, my own method\n",
    "def kFoldCV(dataset, X,y,folds=10):\n",
    "  kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "  accuracies=[]\n",
    "\n",
    "  for train_index, val_index in kf.split(X):\n",
    "    X_train2, X_val2 = X[train_index], X[val_index]\n",
    "    y_train2, y_val2 = y[train_index], y[val_index]\n",
    "\n",
    "    dataset.fit(X_train2, y_train2)\n",
    "    pred2 = dataset.predict(X_val2)\n",
    "    \n",
    "    score = accuracy_score(y_val2, pred2)\n",
    "\n",
    "    print(f'accuracy per fold, kfold (my own method): {score}')\n",
    "    accuracies.append(score)\n",
    "\n",
    "    # print(f'accuracies: {accuracies}')\n",
    "\n",
    "  avg =  np.mean(accuracies)\n",
    "  # print(f\"kFold CV accuracy: {avg}\")\n",
    "  return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte-Carlo cv\n",
    "def mccv(dataset, X, y, n_iterations=10):\n",
    "    accuracies = []\n",
    "    # test = KNN(5)\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        random_indices = np.random.choice(len(X), size=len(X), replace=False)\n",
    "        X_shuffled = X[random_indices]\n",
    "        y_shuffled = y[random_indices]\n",
    "        # print(f'\\nX_shuffled: {X_shuffled}, \\n\\ny_shuffled: {y_shuffled}')\n",
    "\n",
    "        X_train3, X_test3, y_train3, y_test3 = train_test_split(X_shuffled, y_shuffled, test_size=0.3)\n",
    "        dataset.fit(X_train3, y_train3)\n",
    "        y_pred = dataset.predict(X_test3)\n",
    "        accuracy = np.mean(y_pred == y_test3)\n",
    "        print(f'accuracy per fold, mccv (my own method): {accuracy}')\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime\n",
    "def runtime(dataset, X, y):\n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
    "    dataset.fit(X_train4, y_train4)\n",
    "    start_time = time.time()\n",
    "    dataset.predict(X_test4)\n",
    "    end_time = time.time()\n",
    "\n",
    "    total = end_time - start_time\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization\n",
    "def viz(X, y):\n",
    "    df = pd.DataFrame(X)\n",
    "    print(f'\\n\\ndf: {df}')\n",
    "    df['target'] = y\n",
    "    sns.pairplot(df, hue='target', palette='Set1')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89473684 0.85964912 0.92982456 0.87719298 0.96491228 0.89473684\n",
      " 0.87719298 0.94736842 0.9122807  0.96428571]\n",
      "( DecisionTreeClassifier from sklearn) ( kfold cv from sklearn ): 0.9122180451127818\n",
      "\n",
      "accuracy per fold, kfold (my own method): 0.9122807017543859\n",
      "accuracy per fold, kfold (my own method): 0.9473684210526315\n",
      "accuracy per fold, kfold (my own method): 0.9649122807017544\n",
      "accuracy per fold, kfold (my own method): 0.8947368421052632\n",
      "accuracy per fold, kfold (my own method): 0.9122807017543859\n",
      "accuracy per fold, kfold (my own method): 0.8771929824561403\n",
      "accuracy per fold, kfold (my own method): 0.9473684210526315\n",
      "accuracy per fold, kfold (my own method): 0.9649122807017544\n",
      "accuracy per fold, kfold (my own method): 0.9649122807017544\n",
      "accuracy per fold, kfold (my own method): 0.9464285714285714\n",
      "( DecisionTreeClassifier from sklearn) ( kfold cv, my own method ): 0.9332393483709274\n",
      "\n",
      "accuracy per fold, mccv (my own method): 0.935672514619883\n",
      "accuracy per fold, mccv (my own method): 0.9181286549707602\n",
      "accuracy per fold, mccv (my own method): 0.9298245614035088\n",
      "accuracy per fold, mccv (my own method): 0.9473684210526315\n",
      "accuracy per fold, mccv (my own method): 0.9239766081871345\n",
      "accuracy per fold, mccv (my own method): 0.8947368421052632\n",
      "accuracy per fold, mccv (my own method): 0.9590643274853801\n",
      "accuracy per fold, mccv (my own method): 0.9473684210526315\n",
      "accuracy per fold, mccv (my own method): 0.935672514619883\n",
      "accuracy per fold, mccv (my own method): 0.8947368421052632\n",
      " ( DecisionTreeClassifier from sklearn ) ( Monte-Carolo cv ): 0.9286549707602341\n",
      "\n",
      " \n",
      "( DecisionTreeClassifier from sklearn) ( runtime ): 0.0\n",
      "( DecisionTreeClassifier from scratch ) ( loading in data set ):  [1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# outputs\n",
    "print(f'( DecisionTreeClassifier from sklearn) ( kfold cv from sklearn ): {sklearn_cv_score(cancer_test, X, y, 10)}\\n')\n",
    "\n",
    "print(f'( DecisionTreeClassifier from sklearn) ( kfold cv, my own method ): {kFoldCV(cancer_test, X, y)}\\n')\n",
    "\n",
    "print(f' ( DecisionTreeClassifier from sklearn ) ( Monte-Carolo cv ): {mccv(cancer_test, X, y)}\\n')\n",
    "\n",
    "print(f' \\n( DecisionTreeClassifier from sklearn) ( runtime ): {runtime(cancer_test, X, y)}')\n",
    "\n",
    "print(f'( DecisionTreeClassifier from scratch ) ( loading in data set ): ', vals2)\n",
    "\n",
    "# print(f' ( DecisionTreeClassifier from sklearn) ( data visualization ):')\n",
    "# viz(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
